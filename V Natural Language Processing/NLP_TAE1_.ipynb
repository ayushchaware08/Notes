{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFXNfOaOV+53pjxXegGO94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushchaware08/Notes/blob/main/V%20Natural%20Language%20Processing/NLP_TAE1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name** Ayush Chaware\n",
        "\n",
        "**Roll no.**: 22\n",
        "\n",
        "**section** A"
      ],
      "metadata": {
        "id": "Uo14gUmLptR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZXXTrIw5vOI",
        "outputId": "f5d0036b-f426-4e25-b525-43a6cb116cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**English Coupus**"
      ],
      "metadata": {
        "id": "5I81eCxZ9eUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_english = \" AI chatbot is fed input data which it interprets and translates into a relevant output. ChatGPT was created by OpenAI\"\n",
        "corpus_english.lower()"
      ],
      "metadata": {
        "id": "DtGigC736tKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc2db795-4b87-4316-e1b8-f08abac29f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ai chatbot is fed input data which it interprets and translates into a relevant output. chatgpt was created by openai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engtoken = nltk.word_tokenize(corpus_english)\n",
        "print(\"word Tokenize: \",engtoken)\n",
        "print(\"Sentence Tokenize: \",nltk.sent_tokenize(corpus_english))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W3NibIR7SeU",
        "outputId": "896f30ae-340e-45ff-a751-973c15f6bcb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word Tokenize:  ['AI', 'chatbot', 'is', 'fed', 'input', 'data', 'which', 'it', 'interprets', 'and', 'translates', 'into', 'a', 'relevant', 'output', '.', 'ChatGPT', 'was', 'created', 'by', 'OpenAI']\n",
            "Sentence Tokenize:  [' AI chatbot is fed input data which it interprets and translates into a relevant output.', 'ChatGPT was created by OpenAI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charactor Tokanization\n",
        "tokens = [char for char in corpus_english]\n",
        "print(\"Charactor Tokens: \",tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q2pcD1ntTMy",
        "outputId": "d8cf7258-ec1e-4d3b-b038-1e4c550e4573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charactor Tokens:  [' ', 'A', 'I', ' ', 'c', 'h', 'a', 't', 'b', 'o', 't', ' ', 'i', 's', ' ', 'f', 'e', 'd', ' ', 'i', 'n', 'p', 'u', 't', ' ', 'd', 'a', 't', 'a', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 'i', 't', ' ', 'i', 'n', 't', 'e', 'r', 'p', 'r', 'e', 't', 's', ' ', 'a', 'n', 'd', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'e', 's', ' ', 'i', 'n', 't', 'o', ' ', 'a', ' ', 'r', 'e', 'l', 'e', 'v', 'a', 'n', 't', ' ', 'o', 'u', 't', 'p', 'u', 't', '.', ' ', 'C', 'h', 'a', 't', 'G', 'P', 'T', ' ', 'w', 'a', 's', ' ', 'c', 'r', 'e', 'a', 't', 'e', 'd', ' ', 'b', 'y', ' ', 'O', 'p', 'e', 'n', 'A', 'I']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Token Count\n",
        "print(\"Token count: \",len(engtoken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt1qZEiesnZW",
        "outputId": "1c3fd902-0630-4c75-e3d4-a5926f0d3816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token count:  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count Frequency\n",
        "from collections import Counter\n",
        "token_counts = Counter(engtoken)\n",
        "print(token_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG-iyMPWFYA9",
        "outputId": "f44c2a0d-3e8f-408b-f30a-b841685bf4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'AI': 1, 'chatbot': 1, 'is': 1, 'fed': 1, 'input': 1, 'data': 1, 'which': 1, 'it': 1, 'interprets': 1, 'and': 1, 'translates': 1, 'into': 1, 'a': 1, 'relevant': 1, 'output': 1, '.': 1, 'ChatGPT': 1, 'was': 1, 'created': 1, 'by': 1, 'OpenAI': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hindi Courpus**"
      ],
      "metadata": {
        "id": "c7NDh7bd9igc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_hindi = \"एआई चैटबॉट को इनपुट डेटा दिया जाता है जिसकी वह व्याख्या करता है और प्रासंगिक आउटपुट में अनुवाद करता है। ChatGPT OpenAI द्वारा बनाया गया था\"\n",
        "hinditoken = nltk.word_tokenize(corpus_hindi)\n",
        "print(\"word Tokenize: \",hinditoken)\n",
        "print(\"Sentence Tokenize: \",nltk.sent_tokenize(corpus_hindi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVxuxiPX7vMk",
        "outputId": "a8e6d74c-70d4-4b12-afac-534faee6296e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word Tokenize:  ['एआई', 'चैटबॉट', 'को', 'इनपुट', 'डेटा', 'दिया', 'जाता', 'है', 'जिसकी', 'वह', 'व्याख्या', 'करता', 'है', 'और', 'प्रासंगिक', 'आउटपुट', 'में', 'अनुवाद', 'करता', 'है।', 'ChatGPT', 'OpenAI', 'द्वारा', 'बनाया', 'गया', 'था']\n",
            "Sentence Tokenize:  ['एआई चैटबॉट को इनपुट डेटा दिया जाता है जिसकी वह व्याख्या करता है और प्रासंगिक आउटपुट में अनुवाद करता है। ChatGPT OpenAI द्वारा बनाया गया था']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charactor Tokanization\n",
        "tokens = [char for char in corpus_hindi]\n",
        "print(\"Charactor Tokens: \",tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQhomGPltpqq",
        "outputId": "356427ce-2a77-47f2-c4fa-0e1d5c1dd2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charactor Tokens:  ['ए', 'आ', 'ई', ' ', 'च', 'ै', 'ट', 'ब', 'ॉ', 'ट', ' ', 'क', 'ो', ' ', 'इ', 'न', 'प', 'ु', 'ट', ' ', 'ड', 'े', 'ट', 'ा', ' ', 'द', 'ि', 'य', 'ा', ' ', 'ज', 'ा', 'त', 'ा', ' ', 'ह', 'ै', ' ', 'ज', 'ि', 'स', 'क', 'ी', ' ', 'व', 'ह', ' ', 'व', '्', 'य', 'ा', 'ख', '्', 'य', 'ा', ' ', 'क', 'र', 'त', 'ा', ' ', 'ह', 'ै', ' ', 'औ', 'र', ' ', 'प', '्', 'र', 'ा', 'स', 'ं', 'ग', 'ि', 'क', ' ', 'आ', 'उ', 'ट', 'प', 'ु', 'ट', ' ', 'म', 'े', 'ं', ' ', 'अ', 'न', 'ु', 'व', 'ा', 'द', ' ', 'क', 'र', 'त', 'ा', ' ', 'ह', 'ै', '।', ' ', 'C', 'h', 'a', 't', 'G', 'P', 'T', ' ', 'O', 'p', 'e', 'n', 'A', 'I', ' ', 'द', '्', 'व', 'ा', 'र', 'ा', ' ', 'ब', 'न', 'ा', 'य', 'ा', ' ', 'ग', 'य', 'ा', ' ', 'थ', 'ा']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Token Count\n",
        "print(\"Token count: \",len(hinditoken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I4D-rda60ez",
        "outputId": "a3cf86d8-cdac-402e-fb79-5180b1f49c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token count:  26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count Frequenc usey\n",
        "from collections import Counter\n",
        "token_counts = Counter(hinditoken)\n",
        "print(token_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg-etMR0FsuF",
        "outputId": "892f74d7-6b57-4e68-e553-f35c656810be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'है': 2, 'करता': 2, 'एआई': 1, 'चैटबॉट': 1, 'को': 1, 'इनपुट': 1, 'डेटा': 1, 'दिया': 1, 'जाता': 1, 'जिसकी': 1, 'वह': 1, 'व्याख्या': 1, 'और': 1, 'प्रासंगिक': 1, 'आउटपुट': 1, 'में': 1, 'अनुवाद': 1, 'है।': 1, 'ChatGPT': 1, 'OpenAI': 1, 'द्वारा': 1, 'बनाया': 1, 'गया': 1, 'था': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**marathi Courpus**"
      ],
      "metadata": {
        "id": "oeLh9CKwCtft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_marathi = \"एआय चॅटबॉटला इनपुट डेटा दिला जातो ज्याचा तो अर्थ लावतो आणि संबंधित आउटपुटमध्ये अनुवादित करतो. ChatGPT OpenAI द्वारे तयार केले गेले\"\n",
        "marathitoken = nltk.word_tokenize(corpus_marathi)\n",
        "print(\"word Tokenize: \",marathitoken)\n",
        "print(\"Sentence Tokenize: \",nltk.sent_tokenize(corpus_marathi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyjPjbVNCwY1",
        "outputId": "0ef749f3-fda7-40da-da02-24785ad766b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word Tokenize:  ['एआय', 'चॅटबॉटला', 'इनपुट', 'डेटा', 'दिला', 'जातो', 'ज्याचा', 'तो', 'अर्थ', 'लावतो', 'आणि', 'संबंधित', 'आउटपुटमध्ये', 'अनुवादित', 'करतो', '.', 'ChatGPT', 'OpenAI', 'द्वारे', 'तयार', 'केले', 'गेले']\n",
            "Sentence Tokenize:  ['एआय चॅटबॉटला इनपुट डेटा दिला जातो ज्याचा तो अर्थ लावतो आणि संबंधित आउटपुटमध्ये अनुवादित करतो.', 'ChatGPT OpenAI द्वारे तयार केले गेले']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charactor Tokanization\n",
        "tokens = [char for char in corpus_marathi]\n",
        "print(\"Charactor Tokens: \",tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0MTF4dgttjj",
        "outputId": "e3b1a379-6995-440c-8dfd-16ef513b1c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charactor Tokens:  ['ए', 'आ', 'य', ' ', 'च', 'ॅ', 'ट', 'ब', 'ॉ', 'ट', 'ल', 'ा', ' ', 'इ', 'न', 'प', 'ु', 'ट', ' ', 'ड', 'े', 'ट', 'ा', ' ', 'द', 'ि', 'ल', 'ा', ' ', 'ज', 'ा', 'त', 'ो', ' ', 'ज', '्', 'य', 'ा', 'च', 'ा', ' ', 'त', 'ो', ' ', 'अ', 'र', '्', 'थ', ' ', 'ल', 'ा', 'व', 'त', 'ो', ' ', 'आ', 'ण', 'ि', ' ', 'स', 'ं', 'ब', 'ं', 'ध', 'ि', 'त', ' ', 'आ', 'उ', 'ट', 'प', 'ु', 'ट', 'म', 'ध', '्', 'य', 'े', ' ', 'अ', 'न', 'ु', 'व', 'ा', 'द', 'ि', 'त', ' ', 'क', 'र', 'त', 'ो', '.', ' ', 'C', 'h', 'a', 't', 'G', 'P', 'T', ' ', 'O', 'p', 'e', 'n', 'A', 'I', ' ', 'द', '्', 'व', 'ा', 'र', 'े', ' ', 'त', 'य', 'ा', 'र', ' ', 'क', 'े', 'ल', 'े', ' ', 'ग', 'े', 'ल', 'े']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Token Count\n",
        "print(\"Token count: \",len(marathitoken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CbMRF2p69yb",
        "outputId": "de94ecbd-5856-46fe-ed54-73feb8988f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token count:  22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count Frequency\n",
        "from collections import Counter\n",
        "token_counts = Counter(marathitoken)\n",
        "print(token_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JCR3Ld8GPtF",
        "outputId": "29fbc026-4265-43b3-d9b1-9ad4efc675a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'एआय': 1, 'चॅटबॉटला': 1, 'इनपुट': 1, 'डेटा': 1, 'दिला': 1, 'जातो': 1, 'ज्याचा': 1, 'तो': 1, 'अर्थ': 1, 'लावतो': 1, 'आणि': 1, 'संबंधित': 1, 'आउटपुटमध्ये': 1, 'अनुवादित': 1, 'करतो': 1, '.': 1, 'ChatGPT': 1, 'OpenAI': 1, 'द्वारे': 1, 'तयार': 1, 'केले': 1, 'गेले': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**German Language**"
      ],
      "metadata": {
        "id": "DpWjIq9IBqlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "!python -m spacy download de_core_news_sm\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxkJns8I_tnV",
        "outputId": "1af6a53c-504b-46fb-c627-6b8a792808c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "courpus_german = \"Der KI-Chatbot erhält Eingabedaten, die er interpretiert und in eine relevante Ausgabe übersetzt. ChatGPT wurde von OpenAI erstellt\"\n",
        "# Word Tokenize\n",
        "doc = nlp(courpus_german)\n",
        "germen_token = [token.text for token in doc]\n",
        "print(\"word Tokenize: \",germen_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNpjiFOVEh04",
        "outputId": "c361ac3f-8187-40aa-f54e-a267b721611d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word Tokenize:  ['Der', 'KI-Chatbot', 'erhält', 'Eingabedaten', ',', 'die', 'er', 'interpretiert', 'und', 'in', 'eine', 'relevante', 'Ausgabe', 'übersetzt', '.', 'ChatGPT', 'wurde', 'von', 'OpenAI', 'erstellt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence Tokenization\n",
        "print(\"Sentence Tokenize: \", nltk.sent_tokenize(courpus_german))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kha-YN4M7EFL",
        "outputId": "e851eda4-392d-4e15-ec79-9fd693ee8c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenize:  ['Der KI-Chatbot erhält Eingabedaten, die er interpretiert und in eine relevante Ausgabe übersetzt.', 'ChatGPT wurde von OpenAI erstellt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count No of Words\n",
        "print(\"Count of Token: \",len(germen_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFEtU-1rvBxo",
        "outputId": "9b48dd6f-b3e1-458e-8517-22cae07dbd89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of Token:  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count Frequency\n",
        "from collections import Counter\n",
        "token_counts = Counter(germen_token)\n",
        "print(token_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzyt1oWaGVVt",
        "outputId": "62ec9ae6-2a70-4682-d603-2c3b765bc545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'Der': 1, 'KI-Chatbot': 1, 'erhält': 1, 'Eingabedaten': 1, ',': 1, 'die': 1, 'er': 1, 'interpretiert': 1, 'und': 1, 'in': 1, 'eine': 1, 'relevante': 1, 'Ausgabe': 1, 'übersetzt': 1, '.': 1, 'ChatGPT': 1, 'wurde': 1, 'von': 1, 'OpenAI': 1, 'erstellt': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spanish Language**\n"
      ],
      "metadata": {
        "id": "bPBRp7kdB61r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caD1Eb8qB0IT",
        "outputId": "168de426-180c-4a63-a1b4-2c6f529b19e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_spanish =\"El chatbot de IA recibe datos de entrada que interpreta y traduce en una salida relevante. ChatGPT fue creado por OpenAI\"\n",
        "doc = nlp(corpus_spanish)\n",
        "# word Tokenize\n",
        "Spanish_tokens = [token.text for token in doc]\n",
        "print(\"word Tokenize: \",Spanish_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQHj5urYEQVV",
        "outputId": "2a32eab2-dfca-4873-e42a-c4a0db13f82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word Tokenize:  ['El', 'chatbot', 'de', 'IA', 'recibe', 'datos', 'de', 'entrada', 'que', 'interpreta', 'y', 'traduce', 'en', 'una', 'salida', 'relevante', '.', 'ChatGPT', 'fue', 'creado', 'por', 'OpenAI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence TOkenization\n",
        "spanish_sentences = nltk.sent_tokenize(corpus_spanish, language='french')\n",
        "print(\"Sentence Tokenize: \", spanish_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFOvGC7x7Odb",
        "outputId": "eb699444-ebbf-4147-e435-b0a1e626afff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenize:  ['El chatbot de IA recibe datos de entrada que interpreta y traduce en una salida relevante.', 'ChatGPT fue creado por OpenAI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count No of Words\n",
        "print(\"Count of Token: \",len(Spanish_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PmjxGjfvT2I",
        "outputId": "fceea431-15ae-4302-e527-8954f30cb320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of Token:  22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count Frequency\n",
        "from collections import Counter\n",
        "token_counts = Counter(Spanish_tokens)\n",
        "print(token_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWZE8PfiDdOs",
        "outputId": "d859d9e5-d126-4049-ee2d-accbf7897459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'de': 2, 'El': 1, 'chatbot': 1, 'IA': 1, 'recibe': 1, 'datos': 1, 'entrada': 1, 'que': 1, 'interpreta': 1, 'y': 1, 'traduce': 1, 'en': 1, 'una': 1, 'salida': 1, 'relevante': 1, '.': 1, 'ChatGPT': 1, 'fue': 1, 'creado': 1, 'por': 1, 'OpenAI': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7VAURZ5-3Qd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}